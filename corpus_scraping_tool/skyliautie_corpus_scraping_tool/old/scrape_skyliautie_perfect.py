import os
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

BASE_URL = "https://sites.google.com/site/skyliautie/"
LIST_URL = "https://sites.google.com/site/skyliautie/shi/lech"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
}

def sanitize_filename(title: str) -> str:
    title = title.strip().lower()
    title = re.sub(r'\s+', '_', title)
    title = re.sub(r'[^\w\-]', '', title)
    return title if title else "untitled"

def extract_riparline_poem(soup: BeautifulSoup) -> str:
    """2025å¹´ç¾åœ¨ã®Google Sitesæ§‹é€ ã«å®Œå…¨å¯¾å¿œã—ãŸæŠ½å‡ºé–¢æ•°"""
    
    # æ–¹æ³•1: <pre>ã‚¿ã‚°ãŒã‚ã‚Œã°å³æ¡ç”¨ï¼ˆå¤ã„ãƒšãƒ¼ã‚¸ç”¨ï¼‰
    pre = soup.find("pre")
    if pre:
        text = pre.get_text(separator="\n").strip()
        if "Ã¡" in text or "Ã©" in text or "'" in text:
            return text

    # æ–¹æ³•2: ç­‰å¹…ãƒ•ã‚©ãƒ³ãƒˆï¼ˆcourier/monospaceï¼‰ã®è¦ç´ ã‚’ã™ã¹ã¦é›†ã‚ã¦å†æ§‹ç¯‰
    poem_parts = []
    for tag in soup.find_all(style=re.compile(r"courier|monospace|Lucida Console", re.I)):
        text = tag.get_text(separator="\n")
        lines = [ln.strip() for ln in text.split("\n") if ln.strip()]
        poem_parts.extend(lines)
    
    if poem_parts:
        return "\n".join(poem_parts)

    # æ–¹æ³•3: ã‚¢ã‚¯ã‚»ãƒ³ãƒˆæ–‡å­—ãƒ»ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ã‚’å«ã‚€è¡Œã‚’å…¨ãƒšãƒ¼ã‚¸ã‹ã‚‰å¾¹åº•çš„ã«é›†ã‚ã‚‹ï¼ˆæœ€çµ‚å…µå™¨ï¼‰
    full_text = soup.get_text(separator="\n")
    lines = []
    for line in full_text.split("\n"):
        s = line.strip()
        if not s:
            continue
        # ãƒªãƒ‘ãƒ©ã‚¤ãƒ³èªã®ç‰¹å¾´ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¢ã‚¯ã‚»ãƒ³ãƒˆ or ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ãŒã‚ã£ã¦ã€æ—¥æœ¬èªãªã—ã€è‹±èªé•·æ–‡ãªã—ï¼‰
        if re.search(r"[Ã¡Ã©Ã­Ã³ÃºÃ½Ã¤Ã«Ã¯Ã¶Ã¼Ã£ÃµÃ±Ã§'â€™Ê»Ê¼Ê¾]", s) and \
           not re.search(r"[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ ]", s) and \
           len(s) < 120 and \
           not s.isascii():
            lines.append(s)
    
    return "\n".join(lines) if lines else ""

def get_poem_title(soup: BeautifulSoup, url: str) -> str:
    if soup.title and " - Skyliautie" in soup.title.string:
        return soup.title.string.split(" - Skyliautie")[0].strip()
    return os.path.basename(url.split("?")[0])

def get_all_poem_links() -> list:
    r = requests.get(LIST_URL, headers=HEADERS, timeout=20)
    r.raise_for_status()
    soup = BeautifulSoup(r.content, "html.parser")
    
    links = []
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if "/shi/lech/" in href and href.count("/") >= 5:  # å€‹åˆ¥è©©ãƒšãƒ¼ã‚¸ã®æ·±ã•
            full_url = urljoin(BASE_URL, href)
            if "?authuser=0" not in full_url:
                full_url += "?authuser=0"
            title = a.get_text(strip=True) or os.path.basename(href.split("?")[0])
            links.append((title, full_url))
    return links

def main():
    os.makedirs("riparline_corpus", exist_ok=True)
    os.chdir("riparline_corpus")
    
    links = get_all_poem_links()
    print(f"æ¤œå‡ºã•ã‚ŒãŸè©©ãƒšãƒ¼ã‚¸: {len(links)}å€‹\n")

    success = 0
    for i, (_, url) in enumerate(links, 1):
        print(f"[{i:02d}/{len(links)}] {url}")
        try:
            r = requests.get(url, headers=HEADERS, timeout=20)
            r.raise_for_status()
            soup = BeautifulSoup(r.content, "html.parser")
            
            title = get_poem_title(soup, url)
            poem = extract_riparline_poem(soup)
            
            if len(poem) < 60:  # ã•ã™ãŒã«çŸ­ã™ããŸã‚‰å¤±æ•—æ‰±ã„ï¼ˆå®Ÿè³ªã“ã‚Œã§æ¼ã‚Œãªã—ï¼‰
                print("    âš ï¸  æŠ½å‡ºå¤±æ•—ã¾ãŸã¯çŸ­ã™ãã‚‹")
                continue
                
            safe_title = sanitize_filename(title)
            filename = f"Skyl.X-Xï¼ˆ{safe_title}ï¼‰.txt"
            counter = 1
            while os.path.exists(filename):
                filename = f"Skyl.X-Xï¼ˆ{safe_title}_{counter}ï¼‰.txt"
                counter += 1
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write(poem + "\n")
            
            print(f"    âœ… ä¿å­˜: {filename}  ({len(poem.splitlines())}è¡Œ)")
            success += 1
            
        except Exception as e:
            print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nğŸ‰ å®Œäº†ï¼ {success}/{len(links)} ä»¶ã‚’ riparline_corpus ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()